{"layout":"article.njk","title":"Using HarperDB with NATS and Kafka for Change Data Capture","date":"2023-06-06T03:00:00.000Z","formattedDate":"2023-6-6","source_link":"https://www.harperdb.io/post/streaming-harperdb-records-with-nats-and-kafka","tags":["harperdb","nats","kafka"],"topics":[{"name":"HarperDB","slug":"harperdb"},{"name":"NATS","slug":"nats"},{"name":"Kafka","slug":"kafka"}],"content":"<p>Change Data Capture (CDC) is a popular design pattern used to track changes in data from a source database and stream those changes to downstream processes. HarperDB, a clustering engine and custom functions database, can be used to implement CDC. In this tutorial, we’ll see how to utilize the internal NATS streaming service and the Fastify Kafka plugin to publish new records to Kafka.</p>\n<p>HarperDB Setup\nTo start, spin up HarperDB with custom functions enabled alongside Kafka and Zookeeper. Add the following contents to <code>docker-compose.yml</code>:</p>\n<pre><code>version: &quot;3.7&quot;\n\nservices:\n  harperdb:\n    image: harperdb/hdb:v2.3.3\n    ports:\n      - &quot;9925:9925&quot;\n      - &quot;9926:9926&quot;\n    volumes:\n      - ./harperdb:/opt/hdb-data\n      - ./harperdb/custom_functions:/opt/hdb/custom_functions\n    environment:\n      - HDB_LICENSE_KEY=YOUR_LICENSE_KEY\n      - HDB_CUSTOM_FUNCTIONS_ENABLED=true\n      - HDB_KAFKA_ENABLED=true\n      - HDB_KAFKA_BOOTSTRAP_SERVERS=kafka:9092\n      - HDB_KAFKA_ZOOKEEPER_CONNECT=zookeeper:2181\n      - HDB_NATS_ENABLED=true\n      - HDB_NATS_URL=nats://nats:4222\n      - HDB_NATS_CLUSTER_ID=test-cluster\n      - HDB_NATS_CLIENT_ID=test-client\n    depends_on:\n      - kafka\n      - zookeeper\n      - nats\n\n  kafka:\n    image: wurstmeister/kafka\n    ports:\n      - &quot;9092:9092&quot;\n    environment:\n      - KAFKA_ADVERTISED_HOST_NAME=kafka\n      - KAFKA_CREATE_TOPICS=test:1:1\n      - KAFKA_ZOOKEEPER_CONNECT=zookeeper:2181\n\n  zookeeper:\n    image: wurstmeister/zookeeper\n    ports:\n      - &quot;2181:2181&quot;\n</code></pre>\n<p>For this example, we’ll store the database contents locally in <code>./harperdb</code> directory. Also, note that we are not specifying <code>CLUSTERING_ENABLED=true</code> in docker-compose. This will break the initial startup, and we’ll configure via Harper Studio console.</p>\n<p>Start up the services via <code>docker-compose up -d</code>.</p>\n<p>Now we need to connect our local instance to Harper Studio. Specify the username and password from the docker compose file as well as port and host.</p>\n<p>After we log in, we can create a cluster user:</p>\n<pre><code>CREATE USER cluster_user WITH PASSWORD &#39;password&#39;;\nGRANT CLUSTER_ADMIN TO cluster_user;\n</code></pre>\n<p>Finally, let’s create a schema and table. We’ll use our favorite <code>dev</code> schema and <code>dog</code> table respectively.</p>\n<p>Custom Functions Setup\nHarperDB has an existing template utilizing the internal NATS stream and publishing to WebSockets: ​​<a href=\"https://github.com/HarperDB-Add-Ons/cf-template-websockets\">https://github.com/HarperDB-Add-Ons/cf-template-websockets</a></p>\n<p>We will modify this setup to publish to Kafka. But first, clone this repo into the <code>custom_function</code> directory of your HarperDB instance.</p>\n<pre><code>cd harperdb/custom_functions\ngit clone https://github.com/HarperDB-Add-Ons/cf-template-websockets.git\n</code></pre>\n<p>To get this working, rename <code>config.json.example</code> to <code>config.json</code> and update our NATS user and pass to one we created via HarperDB Studio. Finally, run <code>npm i</code> to install the dependencies.</p>\n<p>NOTE: HarperDB Studio cannot parse file names with multiple “.” so it may say “File does not exist”. Simply rename the files if you want to see the file contents on the console.</p>\n<p>Now restart HarperDB, and we can use the example client file (<code>client.example.js</code>) to test the WebSocket connection.</p>\n<p>Once we start this function, we should see the message “open!” and adding new records to our <code>dog</code> table will print out the records.</p>\n<p>Modifying to Publish to Kafka\nInstead of publishing messages back to the WebSocket client, let’s now publish JSON messages to Kafka. To do so, install the Fastify Kafka library: <code>npm i fastify-kafkajs</code>.</p>\n<p>Then we can import and register the Kafka client.</p>\n<pre><code>const fastify = require(&#39;fastify&#39;)({ logger: true })\nconst { Kafka } = require(&#39;kafkajs&#39;)\n\nfastify.register(require(&#39;fastify-kafkajs&#39;), {\n  clientId: &#39;my-app&#39;,\n  brokers: [&#39;localhost:9092&#39;]\n})\n</code></pre>\n<p>We can now simply modify the <code>onPublishedMessage</code> function to publish to Kafka instead of writing back to the socket:</p>\n<pre><code>const kafka = fastify.kafka()\nconst producer = kafka.producer()\n\nasync function onPublishedMessage(message) {\n  const { operation, table, record } = message\n  const key = `${table}_${record.id}`\n  const value = JSON.stringify(record)\n  await producer.send({\n    topic: table,\n    messages: [{ key, value }],\n  })\n}\n</code></pre>\n<p>Now restart the server and connect to our WebSocket client again. Publish another message to HarperDB, and we can check that it has been published to Kafka by sshing into the Kafka container and using the <code>kafka-console-consumer</code> binary:</p>\n<pre><code>docker exec -it kafka /opt/kafka/bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic dog --from-beginning\n</code></pre>\n<p>Wrapping Up\nIn this tutorial, we saw how to use the internal NATS stream to listen to changes to data in HarperDB. We then created a Fastify route to subscribe to those tables and publish those new messages to WebSockets and Kafka. You can modify the <code>onPublishedMessage</code> method to publish to multiple topics and also run this WebSocket client in the background to emulate a Debezium-like experience.</p>\n<p>Get Started With HarperDB\nHarperDB is a powerful database that can be used for a variety of use cases. Whether you need to implement CDC or build a real-time application, HarperDB has the features you need. To learn more, check out the HarperDB documentation and start building today.</p>\n"}