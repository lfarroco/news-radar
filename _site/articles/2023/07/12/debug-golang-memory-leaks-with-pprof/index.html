<!DOCTYPE html>
<html lang="en">
	<head>
		<title>Dev Radar</title>

		<meta charset="UTF-8">
		<meta name="viewport" content="width=device-width">
		<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-2361701055964881" crossorigin="anonymous"></script>
		<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
	</head>
	<body>
		<header>
			<nav class="navbar navbar-expand-lg navbar-dark bg-dark">
				<div class="container">
					<a class="navbar-brand" href="/">
						<img src="/logo.png" width="30" height="30" class="d-inline-block align-top" alt="logo"> Dev Radar</a>
					<button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
						<span class="navbar-toggler-icon"></span>
					</button>
					<div class="collapse navbar-collapse" id="navbarSupportedContent">
						<ul class="navbar-nav me-auto mb-2 mb-lg-0">
							<li class="nav-item">
								<a class="nav-link active" aria-current="page" href="/">Home</a>
							</li>
							<li class="nav-item">
								<a class="nav-link" aria-current="page" href="/topics">Topics</a>
							</li>
						</ul>
					</div>
				</div>
			</nav>
		</header>
		<main class="container">

			<ins class="adsbygoogle mb-2" data-ad-client="ca-pub-2361701055964881" data-ad-slot="9315501947" data-ad-format="auto" data-full-width-responsive="true"></ins>

			<article class="card mt-2">
	<div class="card-header">
		<h1 class="mb-0"></h1>
		<div>
			<small>2023/07/12</small>
		</div>

	</div>
	<div class="card-body">
		<div class="disclaimer">
			This article was written by an AI ðŸ¤–. The original article can be found <a href="https://www.codereliant.io/memory-leaks-with-pprof/" target="_blank"> here</a>.
		</div>
		&lt;p&gt;Managing memory effectively is important for the performance of any application. While Golang&amp;apos;s garbage collector typically does an excellent job of managing memory, memory leaks can still occur. A memory leak arises when an application doesn&amp;apos;t release memory back to the operating system, even if it&amp;apos;s no longer in use. In large applications, these leaks can lead to Out of Memory (OOM) errors and can impact application availability.&lt;/p&gt;
&lt;p&gt;In Golang, memory leaks often happen due to infinite loops, improper use of goroutines, or not releasing references to memory once they&amp;apos;re no longer needed. In this post, we&amp;apos;ll discuss how pprof can be used for memory profiling and fixing leaks in Go.&lt;/p&gt;
&lt;h2&gt;Analyze the Signals&lt;/h2&gt;
&lt;p&gt;High memory usage might indicate a memory leak, but you need to confirm this first, since Linux uses an aggressive page caching mechanism which can lead to high reported memory usage (and it can be especially alarming in containerized environments where you have a fairly low resource ceiling). Here are some key signals that can help you understand if you have a problem:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;RSS (Resident Set Size)&lt;/strong&gt;: The amount of memory that the operating system has allocated to the process.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;HeapAlloc&lt;/strong&gt;: The amount of memory allocated by the Go runtime.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;HeapInuse&lt;/strong&gt;: The amount of memory in use by the application&amp;apos;s live objects.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;HeapReleased&lt;/strong&gt;: The amount of memory released back to the operating system.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;By keeping an eye on these metrics and using the relevant commands, you can confirm whether your application is suffering from a memory leak or not.&lt;/p&gt;
&lt;h2&gt;Enable Profiling&lt;/h2&gt;
&lt;p&gt;If you have confirmed that you actually have a leak, the first debugging tool to reach for should be pprof, a built-in Go library for profiling Go programs.&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;net/http/pprof&lt;/code&gt; package allows you to serve runtime profiling data in HTTP format. To use pprof, you need to import &lt;code&gt;_ &amp;quot;net/http/pprof&amp;quot;&lt;/code&gt; in your main package, and start an HTTP server with &lt;code&gt;http.ListenAndServe&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;You can then use &lt;code&gt;go tool pprof&lt;/code&gt; to interactively explore the data.&lt;/p&gt;
&lt;p&gt;Here&amp;apos;s a command to start a pprof session:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-shell&quot;&gt;go tool pprof http://localhost:8080/debug/pprof/heap
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The pprof tool provides various commands to help analyze the profile:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;top&lt;/strong&gt;: Displays the top memory consumers.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;list&lt;/strong&gt;: Shows the source code around a specific function.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;web&lt;/strong&gt;: Opens a web-based visualization of the profile.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Let&amp;apos;s Try It!&lt;/h2&gt;
&lt;p&gt;Consider the following Go HTTP server:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-go&quot;&gt;package main

import (
	&amp;quot;fmt&amp;quot;
	&amp;quot;net/http&amp;quot;
)

type UserCache struct {
	data map[string]string
}

func (uc *UserCache) handleRequest(w http.ResponseWriter, r *http.Request) {
	// Simulate memory leak by not removing old user data from the cache
	userID := r.URL.Query().Get(&amp;quot;user_id&amp;quot;)
	uc.data[userID] = &amp;quot;some data&amp;quot;
	fmt.Fprint(w, &amp;quot;Data stored in cache&amp;quot;)
}

func main() {
	uc := &amp;amp;UserCache{
		data: make(map[string]string),
	}

	http.HandleFunc(&amp;quot;/leaky-endpoint&amp;quot;, uc.handleRequest)
	http.ListenAndServe(&amp;quot;:8080&amp;quot;, nil)
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In this example, the server stores data for each user in the &lt;code&gt;UserCache&lt;/code&gt;. On every request to &lt;code&gt;/leaky-endpoint&lt;/code&gt;, new user data is created and added to the cache. However, there&amp;apos;s no code to remove old user data from the cache.&lt;/p&gt;
&lt;p&gt;You can simulate the leak by bombarding the server with a large number of requests using a tool like curl or ab.&lt;/p&gt;
&lt;p&gt;Once the requests are completed, you can generate a heap profile by executing the following command in another terminal:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-shell&quot;&gt;go tool pprof http://localhost:8080/debug/pprof/heap
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As we can see, &lt;code&gt;handleRequest&lt;/code&gt; is where the most allocations happen. It can also be confirmed by visual representation by doing:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-shell&quot;&gt;go tool pprof -http=:8081 http://localhost:8080/debug/pprof/heap
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let&amp;apos;s look at &lt;code&gt;handleRequest&lt;/code&gt; more closely to identify where the leak comes from.&lt;/p&gt;
&lt;p&gt;We were able to identify the exact line where the allocations happen, so now we can fix it by, for example, introducing a cache eviction policy.&lt;/p&gt;
&lt;h2&gt;Bonus: More Pprof Goodies&lt;/h2&gt;
&lt;p&gt;In addition to the techniques discussed earlier, pprof provides additional features and functionalities that can further enhance your profiling experience. Let&amp;apos;s explore a few of these:&lt;/p&gt;
&lt;h3&gt;Profiling CPU Usage&lt;/h3&gt;
&lt;p&gt;You can profile your application&amp;apos;s CPU usage using the goroutine and threadcreate profiles. To generate a CPU profile, execute the following command:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-shell&quot;&gt;go tool pprof http://localhost:8080/debug/pprof/profile
&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;Profiling Goroutines&lt;/h3&gt;
&lt;p&gt;You can profile the goroutines in your application using the goroutine profile. To generate a goroutine profile, execute the following command:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-shell&quot;&gt;go tool pprof http://localhost:8080/debug/pprof/goroutine
&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;Profiling Mutex Contention&lt;/h3&gt;
&lt;p&gt;You can profile the mutex contention in your application using the mutex profile. To generate a mutex profile, execute the following command:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-shell&quot;&gt;go tool pprof http://localhost:8080/debug/pprof/mutex
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;These additional profiling features can help you gain deeper insights into the performance of your Go applications and identify any bottlenecks or issues that may be affecting their performance.&lt;/p&gt;
&lt;p&gt;In conclusion, pprof is a powerful tool for debugging and profiling memory leaks in Golang applications. By utilizing its features and functionalities, developers can effectively manage memory and optimize the performance of their applications.&lt;/p&gt;
	</div>
</article>

		</main>
		<footer class="footer mt-auto py-3 bg-dark">
			<div class="container">
				<div class="row">
					<div class="col-sm-2">
						<span class="text-muted">2023 | dev-radar</span>
					</div>
					<div class="col-sm-2">
						<svg xmlns="http://www.w3.org/2000/svg" height="1em" viewBox="0 0 496 512">
							<!--! Font Awesome Free 6.4.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license (Commercial License) Copyright 2023 Fonticons, Inc. -->
							<style>
								svg {
									fill: #ffffff;
								}
							</style><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg>
						<a class="text-muted" href="https://github.com/lfarroco/news-radar"> GitHub </a>

					</div>
				</div>
			</footer>
			<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-EVSTQN3/azprG1Anm3QDgpJLIm9Nao0Yz1ztcQTwFspd3yD65VohhpuuCOmLASjC" crossorigin="anonymous">
			<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/js/bootstrap.bundle.min.js" integrity="sha384-MrcW6ZMFYlzcLA8Nl+NtUVF0sA7MsXsP1UyJoMp4YLEuNSfAP+JcXn/tWtIaxVXM" crossorigin="anonymous"></script>
			<link rel="stylesheet" href="/styles.css"/>
			<script>
				(adsbygoogle = window.adsbygoogle || []).push({});
			</script>
		</body>

	</html>